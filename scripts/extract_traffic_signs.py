#!/usr/bin/env python3
"""
ğŸ¯ äº¤é€šæ ‡å¿—æå–è„šæœ¬

ä½¿ç”¨ VLM ç›®æ ‡æ£€æµ‹ï¼Œä»ä¸€æ‰¹å›¾ç‰‡ä¸­æå–æ‰€æœ‰äº¤é€šæ ‡å¿—ï¼Œ
è£å‰ªä¿å­˜ä¸ºå•ç‹¬çš„å›¾ç‰‡ï¼Œæ–¹ä¾¿æ‰‹åŠ¨æ ‡æ³¨åˆ›å»ºè®­ç»ƒæ•°æ®ã€‚

ç”¨æ³•:
    # ä»å•ä¸ªå›¾ç‰‡æå–
    python scripts/extract_traffic_signs.py path/to/image.jpg
    
    # ä»ç›®å½•æ‰¹é‡æå–
    python scripts/extract_traffic_signs.py path/to/frames/ --output extracted_signs/
    
    # æŒ‡å®šæ¨¡å‹
    python scripts/extract_traffic_signs.py path/to/frames/ --model glm
"""

import os
import sys
import argparse
import asyncio
import base64
import io
from pathlib import Path
from typing import List, Tuple
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from PIL import Image
import httpx

from scripts.video_to_dataset_async import (
    MODEL_CONFIGS, 
    DETECTION_PROMPT,
    get_image_size,
    convert_coords,
    image_to_base64_url,
)
from glm_labeling.utils.labels import get_category, normalize_vehicle_label
from glm_labeling.utils.json_utils import parse_llm_json


# ============================================================================
# æ£€æµ‹å‡½æ•°
# ============================================================================

async def detect_image(image_path: str, api_key: str, model_type: str = "glm") -> List[dict]:
    """
    æ£€æµ‹å•å¼ å›¾ç‰‡ä¸­çš„ç›®æ ‡ï¼ˆé’ˆå¯¹ 4K è¿›è¡Œä¼˜åŒ–ï¼šç¼©æ”¾æ£€æµ‹ + åŸå§‹è£å‰ªï¼‰
    
    Returns:
        æ£€æµ‹ç»“æœåˆ—è¡¨
    """
    width, height = get_image_size(image_path)
    model_config = MODEL_CONFIGS.get(model_type, MODEL_CONFIGS["glm"])
    
    # â­ é’ˆå¯¹ 4K è¿›è¡Œä¼˜åŒ–ï¼šå¦‚æœé•¿è¾¹è¶…è¿‡ 2048ï¼Œç¼©æ”¾åå†å‘ç»™ APIï¼Œé¿å… 400 Bad Request
    MAX_DETECTION_SIZE = 2048
    if width > MAX_DETECTION_SIZE or height > MAX_DETECTION_SIZE:
        img = Image.open(image_path).convert("RGB")
        img.thumbnail((MAX_DETECTION_SIZE, MAX_DETECTION_SIZE))
        # è½¬æ¢ç¼©æ”¾åçš„å›¾ä¸º Base64
        buffered = io.BytesIO()
        img.save(buffered, format="JPEG", quality=85)
        img_base64 = base64.b64encode(buffered.getvalue()).decode()
        base64_url = f"data:image/jpeg;base64,{img_base64}"
        img_data_for_gemini = buffered.getvalue()
    else:
        # æ™®é€šå›¾ç‰‡ç›´æ¥è½¬æ¢
        base64_url = image_to_base64_url(image_path)
        img_data_for_gemini = None
    
    if model_config.get("type") == "gemini":
        # Gemini API
        from google import genai
        from google.genai import types
        
        client = genai.Client()
        
        if img_data_for_gemini:
            image_data = img_data_for_gemini
            mime_type = "image/jpeg"
        else:
            with open(image_path, "rb") as f:
                image_data = f.read()
            ext = Path(image_path).suffix.lower()
            mime_types = {".jpg": "image/jpeg", ".jpeg": "image/jpeg", ".png": "image/png"}
            mime_type = mime_types.get(ext, "image/jpeg")
        
        response = client.models.generate_content(
            model=model_config["name"],
            contents=[
                types.Part.from_bytes(data=image_data, mime_type=mime_type),
                DETECTION_PROMPT
            ]
        )
        content = response.text
    else:
        # GLM API
        async with httpx.AsyncClient(
            base_url=model_config["api_base"],
            timeout=httpx.Timeout(60.0, connect=10.0),
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
        ) as client:
            payload = {
                "model": model_config["name"],
                "messages": [{
                    "role": "user",
                    "content": [
                        {"type": "image_url", "image_url": {"url": base64_url}},
                        {"type": "text", "text": DETECTION_PROMPT}
                    ]
                }]
            }
            
            response = await client.post("/chat/completions", json=payload)
            response.raise_for_status()
            data = response.json()
            content = data["choices"][0]["message"]["content"]
    
    # è§£æç»“æœ
    detections = parse_llm_json(content)
    
    if detections is None:
        return []
    
    # åå¤„ç†ï¼Œåªä¿ç•™äº¤é€šæ ‡å¿—
    signs = []
    for det in detections:
        if "label" not in det or "bbox_2d" not in det:
            continue
        
        # â­ å³ä½¿æ£€æµ‹ç”¨çš„æ˜¯ç¼©ç•¥å›¾ï¼Œåªè¦åæ ‡æ˜¯å½’ä¸€åŒ–çš„ (0-1000)ï¼Œ
        # æˆ‘ä»¬ç”¨åŸå§‹å°ºå¯¸ (width, height) è¿˜åŸï¼Œç»“æœå°±æ˜¯å‡†ç¡®çš„ 4K åæ ‡ã€‚
        bbox = convert_coords(det["bbox_2d"], width, height)
        label = det["label"].lower().replace(" ", "_").replace("-", "_")
        category = get_category(label)
        
        # åªä¿ç•™äº¤é€šæ ‡å¿—
        if category == "traffic_sign":
            signs.append({
                "label": label,
                "bbox": bbox,
                "bbox_normalized": det["bbox_2d"]
            })
    
    return signs


def crop_and_save(
    image_path: str, 
    bbox: List[int], 
    output_path: str, 
    padding: int = 10,
    lossless: bool = False
) -> str:
    """
    è£å‰ªå¹¶ä¿å­˜äº¤é€šæ ‡å¿—
    
    Args:
        image_path: åŸå›¾è·¯å¾„
        bbox: è¾¹ç•Œæ¡† [x1, y1, x2, y2]
        output_path: è¾“å‡ºè·¯å¾„
        padding: è¾¹ç•Œæ‰©å±•åƒç´ 
        lossless: æ˜¯å¦æ— æŸä¿å­˜ï¼ˆPNGæ ¼å¼ï¼‰
    
    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    image = Image.open(image_path).convert("RGB")
    
    # æ·»åŠ  padding
    x1 = max(0, bbox[0] - padding)
    y1 = max(0, bbox[1] - padding)
    x2 = min(image.width, bbox[2] + padding)
    y2 = min(image.height, bbox[3] + padding)
    
    # è£å‰ª
    cropped = image.crop((x1, y1, x2, y2))
    
    # ä¿å­˜
    if lossless:
        # PNG æ— æŸä¿å­˜
        output_path = output_path.replace('.jpg', '.png')
        cropped.save(output_path, format='PNG')
    else:
        # JPEG é«˜è´¨é‡ä¿å­˜
        cropped.save(output_path, quality=100, subsampling=0)
    
    return output_path


# ============================================================================
# æ‰¹é‡å¤„ç†
# ============================================================================

async def process_batch(
    image_paths: List[Path],
    output_dir: Path,
    api_key: str,
    model_type: str,
    padding: int,
    max_concurrent: int,
    lossless: bool,
    metadata: list,
    stats: dict,
    retry_round: int = 0
) -> List[dict]:
    """
    å¤„ç†ä¸€æ‰¹å›¾ç‰‡ï¼Œè¿”å›å¤±è´¥çš„å¸§åˆ—è¡¨
    """
    failed_frames = []
    semaphore = asyncio.Semaphore(max_concurrent)
    total = len(image_paths)

    async def process_single(image_path: Path, idx: int):
        """å¤„ç†å•å¼ å›¾ç‰‡"""
        async with semaphore:
            try:
                prefix = f"[é‡è¯•{retry_round}]" if retry_round > 0 else ""
                print(f"{prefix}[{idx+1}/{total}] å¤„ç†: {image_path.name}")

                # æ£€æµ‹
                signs = await detect_image(str(image_path), api_key, model_type)

                if not signs:
                    print(f"   âš ï¸ æœªæ£€æµ‹åˆ°äº¤é€šæ ‡å¿—")
                    stats["processed_images"] += 1
                    stats["signs_per_image"].append(0)
                    return

                print(f"   âœ… æ£€æµ‹åˆ° {len(signs)} ä¸ªäº¤é€šæ ‡å¿—")

                # è£å‰ªå¹¶ä¿å­˜æ¯ä¸ªæ ‡å¿—
                for sign_idx, sign in enumerate(signs):
                    bbox = sign["bbox"]

                    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
                    ext = ".png" if lossless else ".jpg"
                    output_name = f"{image_path.stem}_sign{sign_idx+1}_{bbox[0]}_{bbox[1]}_{bbox[2]}_{bbox[3]}{ext}"
                    output_path = output_dir / output_name

                    # è£å‰ªä¿å­˜
                    crop_and_save(str(image_path), bbox, str(output_path), padding, lossless)

                    stats["total_signs"] += 1
                    stats["extracted_files"].append(str(output_path))

                    # è®°å½•å…ƒæ•°æ®
                    metadata.append({
                        "source_image": str(image_path),
                        "output_file": output_name,
                        "bbox": bbox,
                        "vlm_label": sign["label"],
                        "manual_label": ""
                    })

                    print(f"      ğŸ“ æ ‡å¿— #{sign_idx+1}: {output_name}")

                stats["processed_images"] += 1
                stats["signs_per_image"].append(len(signs))

            except Exception as e:
                print(f"   âŒ å¤„ç†å¤±è´¥: {e}")
                stats["failed_images"] += 1
                failed_frames.append({
                    "frame": str(image_path),
                    "error": str(e)
                })

    # å¹¶å‘å¤„ç†
    tasks = [process_single(p, i) for i, p in enumerate(image_paths)]
    await asyncio.gather(*tasks)

    return failed_frames


async def process_images(
    input_path: str,
    output_dir: str,
    api_key: str,
    model_type: str = "glm",
    padding: int = 10,
    max_concurrent: int = 5,
    lossless: bool = False,
    max_retries: int = 3,
    retry_delay: int = 10
) -> dict:
    """
    æ‰¹é‡å¤„ç†å›¾ç‰‡ï¼Œæå–äº¤é€šæ ‡å¿—ï¼ˆå¸¦è‡ªåŠ¨é‡è¯•ï¼‰

    Args:
        input_path: è¾“å…¥è·¯å¾„ï¼ˆå›¾ç‰‡æˆ–ç›®å½•ï¼‰
        output_dir: è¾“å‡ºç›®å½•
        api_key: API Key
        model_type: æ¨¡å‹ç±»å‹
        padding: è£å‰ªæ—¶çš„è¾¹ç•Œæ‰©å±•
        max_concurrent: æœ€å¤§å¹¶å‘æ•°
        lossless: æ˜¯å¦æ— æŸä¿å­˜ï¼ˆPNGæ ¼å¼ï¼‰
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        retry_delay: é‡è¯•å‰ç­‰å¾…ç§’æ•°

    Returns:
        ç»Ÿè®¡ä¿¡æ¯
    """
    input_path = Path(input_path)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # è·å–æ‰€æœ‰å›¾ç‰‡
    if input_path.is_file():
        image_paths = [input_path]
    else:
        image_paths = sorted(
            list(input_path.glob("*.jpg")) +
            list(input_path.glob("*.jpeg")) +
            list(input_path.glob("*.png"))
        )

    print(f"\n{'='*60}")
    print(f"ğŸ¯ äº¤é€šæ ‡å¿—æå–")
    print(f"{'='*60}")
    print(f"   è¾“å…¥: {input_path}")
    print(f"   è¾“å‡º: {output_dir}")
    print(f"   å›¾ç‰‡æ•°: {len(image_paths)}")
    print(f"   æ¨¡å‹: {model_type}")
    print(f"   å¹¶å‘æ•°: {max_concurrent}")
    print(f"   ä¿å­˜æ ¼å¼: {'PNG (æ— æŸ)' if lossless else 'JPEG (quality=100)'}")
    print(f"   è‡ªåŠ¨é‡è¯•: æœ€å¤š {max_retries} æ¬¡")
    print(f"{'='*60}\n")

    # ç»Ÿè®¡
    stats = {
        "total_images": len(image_paths),
        "processed_images": 0,
        "failed_images": 0,
        "total_signs": 0,
        "signs_per_image": [],
        "extracted_files": []
    }

    # è®°å½•å…ƒæ•°æ®
    metadata = []

    # ç¬¬ä¸€è½®å¤„ç†
    failed_frames = await process_batch(
        image_paths, output_dir, api_key, model_type,
        padding, max_concurrent, lossless, metadata, stats
    )

    # è‡ªåŠ¨é‡è¯•å¤±è´¥çš„å¸§
    retry_round = 0
    while failed_frames and retry_round < max_retries:
        retry_round += 1
        print(f"\n{'='*60}")
        print(f"ğŸ”„ è‡ªåŠ¨é‡è¯• (ç¬¬ {retry_round}/{max_retries} è½®)")
        print(f"   å¤±è´¥å¸§æ•°: {len(failed_frames)}")
        print(f"   ç­‰å¾… {retry_delay} ç§’åå¼€å§‹...")
        print(f"{'='*60}\n")

        await asyncio.sleep(retry_delay)

        # é‡ç½®å¤±è´¥è®¡æ•°ï¼ˆå› ä¸ºè¦é‡æ–°ç»Ÿè®¡ï¼‰
        stats["failed_images"] = 0

        # è·å–å¤±è´¥å¸§çš„è·¯å¾„
        retry_paths = [Path(f["frame"]) for f in failed_frames]

        # é‡è¯•
        failed_frames = await process_batch(
            retry_paths, output_dir, api_key, model_type,
            padding, max_concurrent, lossless, metadata, stats,
            retry_round=retry_round
        )

    # ä¿å­˜å…ƒæ•°æ®
    metadata_path = output_dir / "metadata.json"
    with open(metadata_path, "w", encoding="utf-8") as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)

    # åˆ›å»ºæ ‡æ³¨æ¨¡æ¿
    labels_template_path = output_dir / "labels_template.csv"
    with open(labels_template_path, "w", encoding="utf-8") as f:
        f.write("filename,label\n")
        for item in metadata:
            f.write(f"{item['output_file']},\n")

    # ä¿å­˜æœ€ç»ˆå¤±è´¥å¸§åˆ—è¡¨ï¼ˆå¦‚æœè¿˜æœ‰ï¼‰
    if failed_frames:
        failed_frames_path = output_dir / "failed_frames.json"
        with open(failed_frames_path, "w", encoding="utf-8") as f:
            json.dump(failed_frames, f, indent=2, ensure_ascii=False)

        failed_frames_txt = output_dir / "failed_frames.txt"
        with open(failed_frames_txt, "w", encoding="utf-8") as f:
            for item in failed_frames:
                f.write(Path(item["frame"]).name + "\n")
    else:
        # å¦‚æœå…¨éƒ¨æˆåŠŸï¼Œåˆ é™¤ä¹‹å‰å¯èƒ½å­˜åœ¨çš„å¤±è´¥åˆ—è¡¨æ–‡ä»¶
        failed_frames_path = output_dir / "failed_frames.json"
        failed_frames_txt = output_dir / "failed_frames.txt"
        if failed_frames_path.exists():
            failed_frames_path.unlink()
        if failed_frames_txt.exists():
            failed_frames_txt.unlink()

    # æ‰“å°ç»Ÿè®¡
    print(f"\n{'='*60}")
    print(f"ğŸ“Š æå–å®Œæˆç»Ÿè®¡")
    print(f"{'='*60}")
    print(f"   å¤„ç†å›¾ç‰‡: {stats['processed_images']}/{stats['total_images']}")
    print(f"   å¤±è´¥å›¾ç‰‡: {len(failed_frames)}")
    print(f"   æå–æ ‡å¿—: {stats['total_signs']} ä¸ª")
    print(f"   é‡è¯•è½®æ•°: {retry_round}")
    if stats['signs_per_image']:
        avg = sum(stats['signs_per_image']) / len(stats['signs_per_image'])
        print(f"   å¹³å‡æ¯å›¾: {avg:.1f} ä¸ªæ ‡å¿—")
    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print(f"   æ ‡å¿—å›¾ç‰‡: {output_dir}/")
    print(f"   å…ƒæ•°æ®:   {metadata_path}")
    print(f"   æ ‡æ³¨æ¨¡æ¿: {labels_template_path}")
    if failed_frames:
        print(f"   å¤±è´¥åˆ—è¡¨: {output_dir}/failed_frames.txt ({len(failed_frames)} å¸§)")
    print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print(f"   1. æŸ¥çœ‹æå–çš„æ ‡å¿—å›¾ç‰‡")
    print(f"   2. ç¼–è¾‘ labels_template.csvï¼Œå¡«å†™æ¯å¼ å›¾ç‰‡çš„æ ‡ç­¾")
    print(f"   3. æ ‡ç­¾åº”è¯¥ä½¿ç”¨ raw_data/signs/ ç›®å½•ä¸‹çš„æ–‡ä»¶åï¼ˆä¸å« .pngï¼‰")
    print(f"{'='*60}")

    return stats


# ============================================================================
# å‘½ä»¤è¡Œæ¥å£
# ============================================================================

def main():
    parser = argparse.ArgumentParser(description="ä»å›¾ç‰‡ä¸­æå–äº¤é€šæ ‡å¿—")
    parser.add_argument("input", type=str, help="è¾“å…¥è·¯å¾„ï¼ˆå›¾ç‰‡æˆ–ç›®å½•ï¼‰")
    parser.add_argument("--output", "-o", type=str, default="extracted_signs",
                        help="è¾“å‡ºç›®å½• (é»˜è®¤: extracted_signs)")
    parser.add_argument("--model", type=str, default="glm",
                        choices=["glm", "gemini", "gemini-2.5-flash", "gemini-2.0-flash"],
                        help="æ£€æµ‹æ¨¡å‹ (é»˜è®¤: glm)")
    parser.add_argument("--padding", type=int, default=10,
                        help="è£å‰ªæ—¶çš„è¾¹ç•Œæ‰©å±•åƒç´  (é»˜è®¤: 10)")
    parser.add_argument("--concurrent", type=int, default=5,
                        help="æœ€å¤§å¹¶å‘æ•° (é»˜è®¤: 5)")
    parser.add_argument("--lossless", action="store_true",
                        help="æ— æŸä¿å­˜ï¼ˆPNGæ ¼å¼ï¼‰ï¼Œé»˜è®¤ä¸ºJPEGé«˜è´¨é‡")
    parser.add_argument("--max-retries", type=int, default=3,
                        help="å¤±è´¥å¸§æœ€å¤§é‡è¯•æ¬¡æ•° (é»˜è®¤: 3)")
    parser.add_argument("--retry-delay", type=int, default=10,
                        help="é‡è¯•å‰ç­‰å¾…ç§’æ•° (é»˜è®¤: 10)")
    args = parser.parse_args()

    # æ£€æŸ¥è¾“å…¥è·¯å¾„
    input_path = Path(args.input)
    if not input_path.exists():
        print(f"âŒ è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {input_path}")
        return

    # è·å– API Key
    model_config = MODEL_CONFIGS.get(args.model, MODEL_CONFIGS["glm"])
    api_key_env = model_config["api_key_env"]
    api_key = os.getenv(api_key_env)

    if not api_key:
        print(f"âŒ è¯·è®¾ç½® {api_key_env} ç¯å¢ƒå˜é‡")
        return

    # è¿è¡Œ
    asyncio.run(process_images(
        input_path=args.input,
        output_dir=args.output,
        api_key=api_key,
        model_type=args.model,
        padding=args.padding,
        max_concurrent=args.concurrent,
        lossless=args.lossless,
        max_retries=args.max_retries,
        retry_delay=args.retry_delay
    ))


if __name__ == "__main__":
    main()

