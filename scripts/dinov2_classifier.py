#!/usr/bin/env python3
"""
ğŸ¦– DINOv2 + Chroma äº¤é€šæ ‡å¿—åˆ†ç±»å™¨

ä½¿ç”¨ Meta çš„ DINOv2 æ¨¡å‹è¿›è¡Œç‰¹å¾æå–ï¼Œæ¯” CLIP æ›´å¼ºçš„è§†è§‰è¡¨ç¤ºèƒ½åŠ›ã€‚
DINOv2 é€šè¿‡è‡ªç›‘ç£å­¦ä¹ è·å¾—äº†å‡ºè‰²çš„ç»†ç²’åº¦è§†è§‰ç‰¹å¾ï¼Œç‰¹åˆ«é€‚åˆäº¤é€šæ ‡å¿—åŒ¹é…ã€‚

ä¼˜åŠ¿:
    - æ›´å¼ºçš„è§†è§‰ç‰¹å¾: DINOv2 åœ¨å¤šç§ä¸‹æ¸¸ä»»åŠ¡ä¸Šè¶…è¶Š CLIP
    - æ›´å¥½çš„ç»†ç²’åº¦åŒºåˆ†: å¯¹å½¢çŠ¶ã€é¢œè‰²ã€ç»†èŠ‚çš„æ„ŸçŸ¥æ›´ç²¾ç¡®
    - å¯¹èƒŒæ™¯å¹²æ‰°æ›´é²æ£’: è‡ªç›‘ç£è®­ç»ƒä½¿å…¶å¯¹å¤æ‚èƒŒæ™¯æ›´ä¸æ•æ„Ÿ

ç”¨æ³•:
    # 1. é¦–æ¬¡è¿è¡Œï¼šå»ºç«‹å‘é‡åº“
    python scripts/dinov2_classifier.py --build
    
    # 2. æµ‹è¯•åˆ†ç±»
    python scripts/dinov2_classifier.py --test path/to/sign.jpg
    
    # 3. ä½œä¸ºæ¨¡å—å¯¼å…¥
    from scripts.dinov2_classifier import DINOv2SignClassifier
    classifier = DINOv2SignClassifier()
    label, score = classifier.classify(image_path, bbox)
"""

import os
import sys
from pathlib import Path
from typing import List, Tuple, Optional
import uuid

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

import torch
import torch.nn.functional as F
import numpy as np
from PIL import Image
from torchvision import transforms

# ============================================================================
# é…ç½®
# ============================================================================

# æ ‡å¿—å›¾ç‰‡ç›®å½•
SIGNS_DIR = Path("raw_data/signs")

# Chroma æ•°æ®åº“ç›®å½•ï¼ˆDINOv2 ä¸“ç”¨ï¼‰
CHROMA_DB_DIR = Path("raw_data/chroma_dinov2_db")

# DINOv2 æ¨¡å‹é…ç½®
# å¯é€‰: dinov2_vits14, dinov2_vitb14, dinov2_vitl14, dinov2_vitg14
# vitl14 æ˜¯æ•ˆæœå’Œé€Ÿåº¦çš„è‰¯å¥½å¹³è¡¡ï¼Œvitg14 æœ€å¼ºä½†éœ€è¦æ›´å¤šæ˜¾å­˜
DINOV2_MODEL_NAME = "dinov2_vitl14"

# 69 ä¸ªæ‘©æ‰˜è½¦å®‰å…¨ç›¸å…³æ ‡å¿—ï¼ˆä¸å…¶ä»–åˆ†ç±»å™¨ä¿æŒä¸€è‡´ï¼‰
MOTORCYCLE_SAFETY_SIGNS = [
    "No_motor_cycles_or_motor_tricycles",
    "No_motor_vehicles_except_motor_cyclists_and_motor_tricycles",
    "Parking_place_for_motor_cycles_only",
    "Speed_limit_(in_km_h)",
    "Variable_speed_limit_(in_km_h)",
    "Reduce_speed_now",
    "Keep_in_low_gear",
    "Use_low_gear",
    "Use_low_gear_for_distance_shown",
    "Slippery_road_ahead",
    "Loose_chippings_ahead",
    "Uneven_road_surface_ahead",
    "Road_hump_ahead",
    "Ramp_or_sudden_change_of_road_level_ahead",
    "Ramp_or_sudden_change_of_road_level",
    "Risk_of_falling_or_fallen_rocks_ahead",
    "Road_works_ahead",
    "Bend_to_left_ahead",
    "Double_bend_ahead_first_to_right",
    "Sharp_deviation_of_route_to_left",
    "Steep_hill_downwards_ahead",
    "Steep_hill_upwards_ahead",
    "Road_narrows_on_both_sides_ahead",
    "No_overtaking",
    "No_entry_for_all_vehicles",
    "No_entry_for_vehicles",
    "No_motor_vehicles",
    "No_stopping_at_any_time",
    "No_stopping",
    "One_way_traffic",
    "One_way_road_ahead",
    "Ahead_only",
    "Keep_right_(keep_left_if_symbol_reversed)",
    "Stop_and_give_way",
    "Give_way_to_traffic_on_major_road",
    "Distance_to__Stop__line",
    "Distance_to__Give_way__line",
    "Stop_or_give_way_ahead_(with_distance_to_line_ahead_given_below)",
    "Cross_roads_ahead",
    "T-junction_ahead",
    "Side_road_to_left_ahead",
    "Staggered_junction_ahead",
    "Traffic_merging_from_left",
    "Merging_into_main_traffic_on_left",
    "Two-way_traffic_ahead",
    "Two-way_traffic_across_a_one-way_road_ahead",
    "Traffic_lights_ahead",
    "Traffic_signals_ahead",
    "Red_light_camera_control_zone",
    "Red_light_speed_camera_ahead",
    "Prepare_to_stop_if_signalled_to_do_so",
    "Vehicles_must_stop_at_the_sign_(sign_used_by_police)",
    "Pedestrian_crossing_ahead",
    "Pedestrians_Ahead",
    "Pedestrian_on_or_crossing_road_ahead",
    "Children_ahead",
    "School_ahead",
    "Playground_ahead",
    "Cyclists_ahead",
    "Disabled_persons_ahead",
    "Visually_impaired_persons_ahead",
    "Traffic_Accident_blackspot_ahead",
    "Pedestrian_Accident_blackspot_ahead",
    "Fog_or_mist_ahead",
    "Restricted_headroom_ahead",
    "No_vehicles_over_height_shown_(including_load)",
    "No_vehicles_over_width_shown_(including_load)",
    "No_vehicles_over_gross_vehicle_weight_shown_(including_load)",
    "No_vehicles_over_axle_weight_shown_(including_load)",
]


# ============================================================================
# DINOv2 æ¨¡å‹å°è£…
# ============================================================================

class DINOv2Encoder:
    """DINOv2 å›¾åƒç¼–ç å™¨"""
    
    def __init__(self, model_name: str = DINOV2_MODEL_NAME):
        """
        åˆå§‹åŒ– DINOv2 æ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°
                - dinov2_vits14: Small (21M params, æœ€å¿«)
                - dinov2_vitb14: Base (86M params)
                - dinov2_vitl14: Large (300M params, æ¨è)
                - dinov2_vitg14: Giant (1.1B params, æœ€å¼º)
        """
        print(f"ğŸ¦– åŠ è½½ DINOv2 æ¨¡å‹: {model_name}")
        
        self.device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
        print(f"   è®¾å¤‡: {self.device}")
        
        # ä» torch hub åŠ è½½ DINOv2
        self.use_timm = False
        self.input_size = 224  # é»˜è®¤ hub æ¨¡å‹è¾“å…¥å¤§å°
        
        try:
            # å…ˆå°è¯•ä»ç¼“å­˜åŠ è½½
            self.model = torch.hub.load('facebookresearch/dinov2', model_name, trust_repo=True)
        except Exception as e:
            print(f"   âš ï¸ ä» hub åŠ è½½å¤±è´¥: {e}")
            print(f"   å°è¯•ä½¿ç”¨æœ¬åœ° timm æ¨¡å‹...")
            # å¤‡é€‰æ–¹æ¡ˆï¼šä½¿ç”¨ timm åŠ è½½ç±»ä¼¼æ¨¡å‹
            try:
                import timm
                # ä½¿ç”¨ timm çš„ ViT æ¨¡å‹ä½œä¸ºæ›¿ä»£
                timm_model_map = {
                    "dinov2_vits14": "vit_small_patch14_dinov2.lvd142m",
                    "dinov2_vitb14": "vit_base_patch14_dinov2.lvd142m",
                    "dinov2_vitl14": "vit_large_patch14_dinov2.lvd142m",
                    "dinov2_vitg14": "vit_giant_patch14_dinov2.lvd142m",
                }
                timm_name = timm_model_map.get(model_name, "vit_large_patch14_dinov2.lvd142m")
                print(f"   ä½¿ç”¨ timm æ¨¡å‹: {timm_name}")
                self.model = timm.create_model(timm_name, pretrained=True, num_classes=0)
                self.use_timm = True
                self.input_size = 518  # timm DINOv2 éœ€è¦ 518x518
            except Exception as e2:
                raise RuntimeError(f"æ— æ³•åŠ è½½ DINOv2 æ¨¡å‹: {e}, {e2}")
        
        self.model = self.model.to(self.device)
        self.model.eval()
        
        # DINOv2 é¢„å¤„ç† - æ ¹æ®æ¨¡å‹ç±»å‹è°ƒæ•´è¾“å…¥å¤§å°
        resize_size = int(self.input_size * 256 / 224)  # ä¿æŒç¼©æ”¾æ¯”ä¾‹
        self.transform = transforms.Compose([
            transforms.Resize(resize_size, interpolation=transforms.InterpolationMode.BICUBIC),
            transforms.CenterCrop(self.input_size),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ])
        
        print(f"   âœ… DINOv2 æ¨¡å‹åŠ è½½å®Œæˆ (è¾“å…¥: {self.input_size}x{self.input_size})")
    
    def encode_image(self, image: Image.Image) -> np.ndarray:
        """
        ç¼–ç å•å¼ å›¾ç‰‡
        
        Args:
            image: PIL Image å¯¹è±¡
        
        Returns:
            å½’ä¸€åŒ–åçš„ç‰¹å¾å‘é‡ (numpy array)
        """
        with torch.no_grad():
            # é¢„å¤„ç†
            image_input = self.transform(image).unsqueeze(0).to(self.device)
            
            # æå–ç‰¹å¾ (CLS token)
            features = self.model(image_input)
            
            # L2 å½’ä¸€åŒ–
            features = F.normalize(features, p=2, dim=-1)
            
            return features.cpu().numpy().flatten()
    
    def encode_image_path(self, image_path: str) -> np.ndarray:
        """ä»è·¯å¾„åŠ è½½å¹¶ç¼–ç å›¾ç‰‡"""
        image = Image.open(image_path).convert("RGB")
        return self.encode_image(image)


# ============================================================================
# Chroma å‘é‡æ•°æ®åº“å°è£…
# ============================================================================

class SignVectorDB:
    """äº¤é€šæ ‡å¿—å‘é‡æ•°æ®åº“"""
    
    def __init__(self, db_dir: Path = CHROMA_DB_DIR, collection_name: str = "traffic_signs_dinov2"):
        """
        åˆå§‹åŒ– Chroma æ•°æ®åº“
        
        Args:
            db_dir: æ•°æ®åº“å­˜å‚¨ç›®å½•
            collection_name: é›†åˆåç§°
        """
        try:
            import chromadb
            from chromadb.config import Settings
        except ImportError:
            raise ImportError("è¯·å®‰è£… chromadb: pip install chromadb")
        
        self.db_dir = Path(db_dir)
        self.db_dir.mkdir(parents=True, exist_ok=True)
        
        # ä½¿ç”¨æŒä¹…åŒ–å®¢æˆ·ç«¯
        self.client = chromadb.PersistentClient(
            path=str(self.db_dir),
            settings=Settings(anonymized_telemetry=False)
        )
        
        # è·å–æˆ–åˆ›å»ºé›†åˆï¼ˆä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
        self.collection = self.client.get_or_create_collection(
            name=collection_name,
            metadata={"hnsw:space": "cosine"}
        )
        
        print(f"ğŸ“¦ Chroma æ•°æ®åº“: {self.db_dir}")
        print(f"   é›†åˆ: {collection_name} ({self.collection.count()} æ¡è®°å½•)")
    
    def add_signs(self, embeddings: List[np.ndarray], labels: List[str], image_paths: List[str]):
        """
        æ‰¹é‡æ·»åŠ æ ‡å¿—å‘é‡
        
        Args:
            embeddings: ç‰¹å¾å‘é‡åˆ—è¡¨
            labels: æ ‡ç­¾åˆ—è¡¨
            image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
        """
        ids = [f"sign_{i}_{label[:50]}" for i, label in enumerate(labels)]
        
        self.collection.add(
            ids=ids,
            embeddings=[e.tolist() for e in embeddings],
            metadatas=[{"label": label, "image_path": path} for label, path in zip(labels, image_paths)],
            documents=labels
        )
        
        print(f"   âœ… æ·»åŠ  {len(labels)} ä¸ªæ ‡å¿—å‘é‡")
    
    def query(self, query_embedding: np.ndarray, top_k: int = 1) -> List[dict]:
        """
        æŸ¥è¯¢æœ€ç›¸ä¼¼çš„æ ‡å¿—
        
        Args:
            query_embedding: æŸ¥è¯¢å‘é‡
            top_k: è¿”å›å‰ k ä¸ªç»“æœ
        
        Returns:
            ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« label, score, image_path
        """
        results = self.collection.query(
            query_embeddings=[query_embedding.tolist()],
            n_results=top_k,
            include=["metadatas", "distances"]
        )
        
        output = []
        if results["metadatas"] and results["distances"]:
            for metadata, distance in zip(results["metadatas"][0], results["distances"][0]):
                # Chroma ä½¿ç”¨è·ç¦»ï¼Œä½™å¼¦ç›¸ä¼¼åº¦ = 1 - distance
                score = 1 - distance
                output.append({
                    "label": metadata["label"],
                    "score": score,
                    "image_path": metadata.get("image_path", "")
                })
        
        return output
    
    def clear(self):
        """æ¸…ç©ºé›†åˆ"""
        collection_name = "traffic_signs_dinov2"
        self.client.delete_collection(collection_name)
        self.collection = self.client.create_collection(
            name=collection_name,
            metadata={"hnsw:space": "cosine"}
        )
        print("   ğŸ—‘ï¸ å·²æ¸…ç©ºå‘é‡åº“")


# ============================================================================
# ä¸»åˆ†ç±»å™¨
# ============================================================================

class DINOv2SignClassifier:
    """
    DINOv2 + Chroma äº¤é€šæ ‡å¿—åˆ†ç±»å™¨
    
    ç”¨æ³•:
        classifier = DINOv2SignClassifier()
        
        # å»ºåº“ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
        classifier.build_database()
        
        # åˆ†ç±»
        label, score = classifier.classify("image.jpg", [100, 200, 150, 250])
    """
    
    def __init__(
        self, 
        signs_dir: Path = SIGNS_DIR,
        db_dir: Path = CHROMA_DB_DIR,
        model_name: str = DINOV2_MODEL_NAME,
        use_69_signs: bool = True,
        similarity_threshold: float = 0.5
    ):
        """
        åˆå§‹åŒ–åˆ†ç±»å™¨
        
        Args:
            signs_dir: æ ‡å¿—å›¾ç‰‡ç›®å½•
            db_dir: å‘é‡æ•°æ®åº“ç›®å½•
            model_name: DINOv2 æ¨¡å‹åç§°
            use_69_signs: æ˜¯å¦åªä½¿ç”¨ 69 ä¸ªæ‘©æ‰˜è½¦å®‰å…¨ç›¸å…³æ ‡å¿—
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼è¿”å› "other"
        """
        self.signs_dir = Path(signs_dir)
        self.db_dir = Path(db_dir)
        self.model_name = model_name
        self.use_69_signs = use_69_signs
        self.similarity_threshold = similarity_threshold
        
        # æ‡’åŠ è½½
        self._encoder = None
        self._db = None
    
    @property
    def encoder(self) -> DINOv2Encoder:
        """æ‡’åŠ è½½ DINOv2 ç¼–ç å™¨"""
        if self._encoder is None:
            self._encoder = DINOv2Encoder(self.model_name)
        return self._encoder
    
    @property
    def db(self) -> SignVectorDB:
        """æ‡’åŠ è½½å‘é‡æ•°æ®åº“"""
        if self._db is None:
            self._db = SignVectorDB(self.db_dir)
        return self._db
    
    def build_database(self, rebuild: bool = False):
        """
        å»ºç«‹å‘é‡æ•°æ®åº“
        
        Args:
            rebuild: æ˜¯å¦é‡å»ºï¼ˆæ¸…ç©ºç°æœ‰æ•°æ®ï¼‰
        """
        print("=" * 60)
        print("ğŸ—ï¸ å»ºç«‹ DINOv2 äº¤é€šæ ‡å¿—å‘é‡æ•°æ®åº“")
        print("=" * 60)
        
        if rebuild:
            self.db.clear()
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®
        if self.db.collection.count() > 0:
            print(f"   âš ï¸ æ•°æ®åº“å·²æœ‰ {self.db.collection.count()} æ¡è®°å½•ï¼Œè·³è¿‡å»ºåº“")
            print(f"   è‹¥éœ€é‡å»ºï¼Œè¯·ä½¿ç”¨ --rebuild å‚æ•°")
            return
        
        # è·å–æ ‡å¿—å›¾ç‰‡
        if self.use_69_signs:
            sign_names = MOTORCYCLE_SAFETY_SIGNS
            print(f"   ğŸ“‹ ä½¿ç”¨ 69 ä¸ªæ‘©æ‰˜è½¦å®‰å…¨ç›¸å…³æ ‡å¿—")
        else:
            sign_names = [f.stem for f in sorted(self.signs_dir.glob("*.png"))]
            print(f"   ğŸ“‹ ä½¿ç”¨å…¨éƒ¨ {len(sign_names)} ä¸ªæ ‡å¿—")
        
        # ç¼–ç å¹¶æ·»åŠ 
        embeddings = []
        labels = []
        paths = []
        
        print(f"\nğŸ”„ ç¼–ç æ ‡å¿—å›¾ç‰‡...")
        
        # å…ˆç¡®ä¿ç¼–ç å™¨åŠ è½½æˆåŠŸ
        try:
            _ = self.encoder  # è§¦å‘æ‡’åŠ è½½
        except Exception as e:
            print(f"   âŒ æ— æ³•åŠ è½½ DINOv2 æ¨¡å‹: {e}")
            return
        
        for i, name in enumerate(sign_names):
            # æŸ¥æ‰¾å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶
            image_path = self.signs_dir / f"{name}.png"
            if not image_path.exists():
                # å°è¯•æ¨¡ç³ŠåŒ¹é…
                matches = list(self.signs_dir.glob(f"{name}*.png"))
                if matches:
                    image_path = matches[0]
                else:
                    print(f"   âš ï¸ æœªæ‰¾åˆ°å›¾ç‰‡: {name}")
                    continue
            
            try:
                embedding = self.encoder.encode_image_path(str(image_path))
                embeddings.append(embedding)
                labels.append(name)
                paths.append(str(image_path))
                
                if (i + 1) % 10 == 0:
                    print(f"   å·²å¤„ç† {i + 1}/{len(sign_names)}")
                    
            except Exception as e:
                print(f"   âŒ ç¼–ç å¤±è´¥ {name}: {e}")
        
        # æ·»åŠ åˆ°æ•°æ®åº“
        print(f"\nğŸ’¾ æ·»åŠ åˆ°å‘é‡æ•°æ®åº“...")
        self.db.add_signs(embeddings, labels, paths)
        
        print(f"\nâœ… å»ºåº“å®Œæˆï¼å…± {len(labels)} ä¸ªæ ‡å¿—")
        print("=" * 60)
    
    def classify(
        self, 
        image_path: str, 
        bbox: List[int] = None,
        top_k: int = 1
    ) -> Tuple[str, float]:
        """
        åˆ†ç±»äº¤é€šæ ‡å¿—
        
        Args:
            image_path: åŸå›¾è·¯å¾„
            bbox: è¾¹ç•Œæ¡† [x1, y1, x2, y2]ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨æ•´å¼ å›¾ç‰‡
            top_k: è¿”å›å‰ k ä¸ªç»“æœ
        
        Returns:
            (label, score) - æ ‡ç­¾å’Œç›¸ä¼¼åº¦åˆ†æ•°
        """
        # åŠ è½½å¹¶è£å‰ªå›¾ç‰‡
        image = Image.open(image_path).convert("RGB")
        
        if bbox:
            padding = 5
            x1 = max(0, bbox[0] - padding)
            y1 = max(0, bbox[1] - padding)
            x2 = min(image.width, bbox[2] + padding)
            y2 = min(image.height, bbox[3] + padding)
            image = image.crop((x1, y1, x2, y2))
        
        # ç¼–ç 
        query_embedding = self.encoder.encode_image(image)
        
        # æŸ¥è¯¢
        results = self.db.query(query_embedding, top_k=top_k)
        
        if not results:
            return "other", 0.0
        
        top_result = results[0]
        
        # æ£€æŸ¥é˜ˆå€¼
        if top_result["score"] < self.similarity_threshold:
            return "other", top_result["score"]
        
        return top_result["label"], top_result["score"]
    
    def classify_with_details(
        self, 
        image_path: str, 
        bbox: List[int] = None,
        top_k: int = 3
    ) -> List[dict]:
        """
        åˆ†ç±»å¹¶è¿”å›è¯¦ç»†ç»“æœ
        
        Returns:
            Top-K ç»“æœåˆ—è¡¨
        """
        image = Image.open(image_path).convert("RGB")
        
        if bbox:
            padding = 5
            x1 = max(0, bbox[0] - padding)
            y1 = max(0, bbox[1] - padding)
            x2 = min(image.width, bbox[2] + padding)
            y2 = min(image.height, bbox[3] + padding)
            image = image.crop((x1, y1, x2, y2))
        
        query_embedding = self.encoder.encode_image(image)
        return self.db.query(query_embedding, top_k=top_k)
    
    def classify_with_details_from_image(
        self, 
        image: Image.Image,
        top_k: int = 3
    ) -> List[dict]:
        """
        ä» PIL Image ç›´æ¥åˆ†ç±»å¹¶è¿”å›è¯¦ç»†ç»“æœ
        
        Args:
            image: PIL Image å¯¹è±¡
            top_k: è¿”å›å‰ k ä¸ªç»“æœ
        
        Returns:
            Top-K ç»“æœåˆ—è¡¨
        """
        query_embedding = self.encoder.encode_image(image.convert("RGB"))
        return self.db.query(query_embedding, top_k=top_k)


# ============================================================================
# å‘½ä»¤è¡Œæ¥å£
# ============================================================================

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="DINOv2 + Chroma äº¤é€šæ ‡å¿—åˆ†ç±»å™¨")
    parser.add_argument("--build", action="store_true", help="å»ºç«‹å‘é‡æ•°æ®åº“")
    parser.add_argument("--rebuild", action="store_true", help="é‡å»ºå‘é‡æ•°æ®åº“ï¼ˆæ¸…ç©ºç°æœ‰æ•°æ®ï¼‰")
    parser.add_argument("--test", type=str, help="æµ‹è¯•åˆ†ç±»ï¼ŒæŒ‡å®šå›¾ç‰‡è·¯å¾„")
    parser.add_argument("--bbox", type=str, help="è¾¹ç•Œæ¡†ï¼Œæ ¼å¼: x1,y1,x2,y2")
    parser.add_argument("--all-signs", action="store_true", help="ä½¿ç”¨å…¨éƒ¨ 188 ä¸ªæ ‡å¿—ï¼ˆé»˜è®¤åªç”¨ 69 ä¸ªï¼‰")
    parser.add_argument("--top-k", type=int, default=5, help="è¿”å›å‰ K ä¸ªç»“æœï¼ˆé»˜è®¤ 5ï¼‰")
    parser.add_argument("--model", type=str, default=DINOV2_MODEL_NAME,
                       choices=["dinov2_vits14", "dinov2_vitb14", "dinov2_vitl14", "dinov2_vitg14"],
                       help=f"DINOv2 æ¨¡å‹ (é»˜è®¤: {DINOV2_MODEL_NAME})")
    args = parser.parse_args()
    
    classifier = DINOv2SignClassifier(
        use_69_signs=not args.all_signs,
        model_name=args.model
    )
    
    if args.build or args.rebuild:
        classifier.build_database(rebuild=args.rebuild)
    
    if args.test:
        print("\n" + "=" * 60)
        print(f"ğŸ” æµ‹è¯•åˆ†ç±»: {args.test}")
        print("=" * 60)
        
        bbox = None
        if args.bbox:
            bbox = [int(x) for x in args.bbox.split(",")]
            print(f"   è¾¹ç•Œæ¡†: {bbox}")
        
        results = classifier.classify_with_details(args.test, bbox, top_k=args.top_k)
        
        print(f"\nğŸ“Š Top-{args.top_k} ç»“æœ:")
        for i, r in enumerate(results):
            emoji = "ğŸ¥‡" if i == 0 else "ğŸ¥ˆ" if i == 1 else "ğŸ¥‰" if i == 2 else "  "
            print(f"   {emoji} [{i+1}] {r['label']}")
            print(f"       ç›¸ä¼¼åº¦: {r['score']:.4f}")
        
        # æœ€ç»ˆæ ‡ç­¾
        label, score = classifier.classify(args.test, bbox)
        print(f"\nğŸ·ï¸ æœ€ç»ˆæ ‡ç­¾: {label} (score: {score:.4f})")
    
    if not args.build and not args.rebuild and not args.test:
        parser.print_help()


if __name__ == "__main__":
    main()

